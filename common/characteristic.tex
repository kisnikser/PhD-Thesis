{\actuality} Решение любой задачи машинного обучения предполагает выбор модели из некоторого семейства моделей, осуществляемый на основе данных, полученных из реального мира. Подавляющее большинство современных моделей машинного обучения являются параметрическими, то есть описываются конечным набором параметров, значения которых определяются в процессе обучения. Выбор оптимальных параметров из допустимого множества осуществляется путем минимизации функции потерь, количественно характеризующей степень несоответствия между предсказаниями модели и наблюдаемыми в реальном мире зависимостями. 

Важно отметить, что функция потерь вычисляется на ограниченной выборке данных из реального мира, и, будучи функцией от параметров модели, она отражает одновременно как свойства самой модели, так и особенности имеющихся данных. Это обстоятельство порождает фундаментальный вопрос о характере взаимосвязи между объемом и свойствами обучающих данных, с одной стороны, и структурой параметрической модели, с другой стороны. В частности, представляет значительный теоретический и практический интерес задача определения минимального объема данных, необходимого для успешного обучения модели заданного семейства.

Ключевой характеристикой, позволяющей исследовать указанные взаимосвязи, является ландшафт функции потерь в пространстве параметров модели~\cite{li2018visualizing,fort2019large,draxler2018essentially}. Ландшафт функции потерь определяет геометрическую структуру множества оптимальных параметров, из которого в процессе оптимизации выбирается конкретное решение, например, с помощью методов стохастического градиентного спуска~\cite{garipov2018loss,chaudhari2019entropy}. 

Таким образом, актуальной научной задачей является систематический анализ взаимосвязей между тремя основными компонентами: параметрической моделью машинного обучения, объемом обучающей выборки (при условии, что данные являются независимыми и одинаково распределенными случайными величинами из некоторого вероятностного распределения) и геометрической структурой множества оптимальных параметров, определяемой через ландшафт функции потерь.

{\aim} данной работы является разработка математических методов для описания законов масштабирования параметрических моделей машинного обучения: классических линейных моделей и современных глубоких нейронных сетей. Для~достижения цели в~работе были поставлены и решены следующие {\tasks}:
\begin{enumerate}[beginpenalty=10000] % https://tex.stackexchange.com/a/476052/104425
  \item Разработать метод на основе бустрапирования функции правдоподобия по подвыборкам для оценки законов масштабирования вероятностой модели линейной регрессии; получить теоретические оценки того, как связано увеличение размера обучающей выборки со стабилизацией математического ожидания и дисперсии функции правподобия.
  \item Разработать метод на основе близости апостериорных распределений параметров модели по подвыборкам для оценки законов масштабирования вероятностной модели линейной регрессии; получить теоретические оценки того, как связано увеличение числа обучающих примеров со стабилизацией апостериорного распределения параметров модели.
  \item Разработать метод на основе стабилизации поверхности функции потерь при увеличении размера обучающей выборки для оценки законов масштабирования матрично-представимых нейронных сетей; предложить и математически обосновать численный метод сравнения значений функции потерь в точке ее минимума при добавлении новых данных.
  \item Разработать численный метод на основе сэмплирования точек в окрестности минимума функции потерь для оценки сходимости ее поверхности при увеличении количества обучающих примеров в нейронных сетях; предложить и математически обосновать метод перехода к подпространству меньшей размерности для увеличения вычислительной эффективности и улучшения оценок на скорость сходимости.
\end{enumerate}

{\novelty}
\begin{enumerate}[beginpenalty=10000] % https://tex.stackexchange.com/a/476052/104425
  \item Впервые предложен метод оценки законов масштабирования вероятностной модели линейной регрессии на основе бустрапирования функции правдоподобия по подвыборкам, отличающийся тем, что не требует построения полной кривой обучения и позволяет получать теоретические оценки стабилизации статистик функции правдоподобия при увеличении объема данных.
  
  \item Впервые предложен метод оценки законов масштабирования вероятностной модели линейной регрессии на основе близости апостериорных распределений параметров модели на подвыборках, отличающийся использованием метрик расхождения вероятностных распределений для количественной характеристики сходимости модели без необходимости многократного полного переобучения.
  
  \item Впервые предложен метод оценки законов масштабирования матрично-представимых нейронных сетей на основе сходимости ландшафта функции потерь. В основе подхода лежит разложение Гаусса "--~Ньютона и спектральный анализ матрицы Гессе нейронной сети. Разработанный метод впервые теоретически объясняет известные эмпирические законы масштабирования нейронных сетей~\autocite{hoffmann2022chinchila}.

  \item Впервые предложен численный метод оценки сходимости ландшафта функции потерь в нейронных сетях на основе сэмплирования точек по Монте "--~Карло в окрестности минимума. Особенность метода заключается в переходе к линейному подпространству, натянутому на наибольшие собственные вектора матрицы Гессе нейронной сети. В отличие от предыдущих подходов, метод обеспечивает вычислительную эффективность при увеличении точности оценок.
\end{enumerate}

{\tinfluence} полученных результатов состоит в оригинальном обосновании существующих эмпирических законов масштабирования параметрических моделей.

{\pinfluence} настоящей работы заключается в применении предложенных методов к определению количества данных, необходимых для обучения параметрических моделей, в том числе современных глубоких нейронных сетей.

{\methods} Для достижения поставленных
в диссертационной работе целей используются:
\begin{enumerate}[beginpenalty=10000]
    \item Методы линейной алгебры, математического и функционального анализа, в том числе матричное дифференцирование, анализ функций многих переменных и спектральный анализ матриц.
    \item Методы теории вероятностей и математической статистики, включая байесовский анализ, анализ сходимости случайных процессов и методы теории оптимизации.
    \item Способы количественной и качественной оценки результатов экспериментов, используемых в области  машинного обучения и математической статистики.
\end{enumerate}

{\defpositions}
\begin{enumerate}[beginpenalty=10000] % https://tex.stackexchange.com/a/476052/104425
  \item Метод оценки законов масштабирования вероятностной модели линейной регрессии на основе бустрапирования функции правдоподобия по подвыборкам, базирующийся на теоретических оценках скорости стабилизации математического ожидания и дисперсии функции правдоподобия; получены верхние границы зависимости требуемого объема выборки от заданной точности оценки параметров.
  
  \item Метод оценки законов масштабирования вероятностной модели линейной регрессии, использующий сходимость KL-дивергенции и функции близости s-score между апостериорными распределениями, построенными по схожим подвыборкам; получены верхние границы зависимости требуемого объема выборки от заданной близости апостериорных распределений.

  \item Метод оценки законов масштабирования матрично-представимых нейронных сетей, основанный на разложении Гаусса "--~Ньютона и спектральном анализе матрицы Гессе нейронной сети; получены оценки на спектральную норму матрицы Гессе для различных архитектур: полносвязной, сверточной и трансформерной.

  \item Численный метод оценки сходимости ландшафта функции потерь в нейронных сетях, имеющий в своей основе сэмплирование точек по Монте "--~Карло и переход к линейному подпространству, натянутому на наибольшие собственные вектора матрицы Гессе нейронной сети.
\end{enumerate}

{\reliability} полученных результатов обеспечивается корректностью
применения апробированного в научной практике математического аппарата теории вероятностей, математической статистики и других смежных теоретических областей, а также экспериментальной проверкой разработанных методов на большом количестве модельных и практических задач машинного обучения. Полученные теоретические результы обосновываются математически строгими доказательствами, а для проведенных вычислительных экспериментов даются детальные описания, обеспечивающие их воспроизводимость. Результаты опубликованы в рецензируемых научных изданиях и в трудах рецензируемых российских и международных конференций по машинному обучению и искусственному интеллекту.

{\probation} Основные результаты работы докладывались и обсуждались на следующих научных конференциях:
\begin{enumerate}
    \item Открытая конференция ИСП РАН, 9--10 декабря, 2025 г.
    \item 22-я Всероссийская конференция с международным участием <<Математические методы распознавания образом (ММРО-2025)>>, Муром, 22--26 сентября, 2025 г.
    \item 67-я Всероссийская научная конференция МФТИ, 31 марта -- 5 апреля, 2025 г.
    \item Открытая конференция ИСП РАН, 11--12 декабря, 2024 г.
    \item 66-я Всероссийская научная конференция МФТИ, 1--6 апреля, 2024 г.
\end{enumerate}

{\contribution} Все приведенные результаты, кроме отдельно оговоренных случаев, получены диссертантом лично при научном руководстве к.ф.-м.н.~А.\,В.~Грабового.

\ifnumequal{\value{bibliosel}}{0}
{%%% Встроенная реализация с загрузкой файла через движок bibtex8. (При желании, внутри можно использовать обычные ссылки, наподобие `\cite{vakbib1,vakbib2}`).
    {\publications} Основные результаты по теме диссертации изложены
    в~XX~печатных изданиях,
    X из которых изданы в журналах, рекомендованных ВАК,
    X "--- в тезисах докладов.
}%
{%%% Реализация пакетом biblatex через движок biber
    \begin{refsection}[bl-author, bl-registered]
        % Это refsection=1.
        % Процитированные здесь работы:
        %  * подсчитываются, для автоматического составления фразы "Основные результаты ..."
        %  * попадают в авторскую библиографию, при usefootcite==0 и стиле `\insertbiblioauthor` или `\insertbiblioauthorgrouped`
        %  * нумеруются там в зависимости от порядка команд `\printbibliography` в этом разделе.
        %  * при использовании `\insertbiblioauthorgrouped`, порядок команд `\printbibliography` в нем должен быть тем же (см. biblio/biblatex.tex)
        %
        % Невидимый библиографический список для подсчета количества публикаций:
        \phantom{\printbibliography[heading=nobibheading, section=1, env=countauthorvak,          keyword=biblioauthorvak]%
        \printbibliography[heading=nobibheading, section=1, env=countauthorwos,          keyword=biblioauthorwos]%
        \printbibliography[heading=nobibheading, section=1, env=countauthorscopus,       keyword=biblioauthorscopus]%
        \printbibliography[heading=nobibheading, section=1, env=countauthorconf,         keyword=biblioauthorconf]%
        \printbibliography[heading=nobibheading, section=1, env=countauthorother,        keyword=biblioauthorother]%
        \printbibliography[heading=nobibheading, section=1, env=countregistered,         keyword=biblioregistered]%
        \printbibliography[heading=nobibheading, section=1, env=countauthorpatent,       keyword=biblioauthorpatent]%
        \printbibliography[heading=nobibheading, section=1, env=countauthorprogram,      keyword=biblioauthorprogram]%
        \printbibliography[heading=nobibheading, section=1, env=countauthor,             keyword=biblioauthor]%
        \printbibliography[heading=nobibheading, section=1, env=countauthorvakscopuswos, filter=vakscopuswos]%
        \printbibliography[heading=nobibheading, section=1, env=countauthorscopuswos,    filter=scopuswos]}%
        %
        \nocite{*}%
        %
        % {\publications} Основные результаты по теме диссертации изложены в~\arabic{citeauthor}~печатных изданиях~\cite{},
        % \arabic{citeauthorvak} из которых изданы в журналах, рекомендованных ВАК%
        % \ifnum \value{citeauthorscopuswos}>0%
        %     , \arabic{citeauthorscopuswos} "--- в~периодических научных журналах, индексируемых Web of~Science и Scopus%
        % \fi%
        % \ifnum \value{citeauthorconf}>0%
        %     , \arabic{citeauthorconf} "--- в~тезисах докладов.
        % \else%
        %     .
        % \fi%
        % \ifnum \value{citeregistered}=1%
        %     \ifnum \value{citeauthorpatent}=1%
        %         Зарегистрирован \arabic{citeauthorpatent} патент.
        %     \fi%
        %     \ifnum \value{citeauthorprogram}=1%
        %         Зарегистрирована \arabic{citeauthorprogram} программа для ЭВМ.
        %     \fi%
        % \fi%
        % \ifnum \value{citeregistered}>1%
        %     Зарегистрированы\ %
        %     \ifnum \value{citeauthorpatent}>0%
        %     \formbytotal{citeauthorpatent}{патент}{}{а}{}%
        %     \ifnum \value{citeauthorprogram}=0 . \else \ и~\fi%
        %     \fi%
        %     \ifnum \value{citeauthorprogram}>0%
        %     \formbytotal{citeauthorprogram}{программ}{а}{ы}{} для ЭВМ.
        %     \fi%
        % \fi%
        {\publications} \ifsynopsis\textit{Список публикаций приведен в конце автореферата. }\else\textit{Список публикаций приведен в конце диссертации. }\fi Основные результаты по теме диссертации изложены в~\arabic{citeauthor}~научных работах, из которых~\arabic{citeauthorscopus} "--- в~периодических научных журналах, индексируемых Scopus и Web of~Science, а остальные~\arabic{citeauthorconf} "--- в~тезисах докладов российских и международных конференций.
        % К публикациям, в которых излагаются основные научные результаты диссертации на соискание ученой
        % степени, в рецензируемых изданиях приравниваются патенты на изобретения, патенты (свидетельства) на
        % полезную модель, патенты на промышленный образец, патенты на селекционные достижения, свидетельства
        % на программу для электронных вычислительных машин, базу данных, топологию интегральных микросхем,
        % зарегистрированные в установленном порядке.(в ред. Постановления Правительства РФ от 21.04.2016 N 335)
    \end{refsection}%
    \begin{refsection}[bl-author, bl-registered]
        % Это refsection=2.
        % Процитированные здесь работы:
        %  * попадают в авторскую библиографию, при usefootcite==0 и стиле `\insertbiblioauthorimportant`.
        %  * ни на что не влияют в противном случае
    \end{refsection}%
        %
        % Все, что вне этих двух refsection, это refsection=0,
        %  * для диссертации - это нормальные ссылки, попадающие в обычную библиографию
        %  * для автореферата:
        %     * при usefootcite==0, ссылка корректно сработает только для источника из `external.bib`. Для своих работ --- напечатает "[0]" (и даже Warning не вылезет).
        %     * при usefootcite==1, ссылка сработает нормально. В авторской библиографии будут только процитированные в refsection=0 работы.
}